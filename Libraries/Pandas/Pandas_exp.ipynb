{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np                # for manipulation of examples\n",
    "#import cprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
    "                   columns=['a', 'b', 'c'])                     # another way to do this is with a dictionary - write this down here too  \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mastery of Indexing\n",
    "AWLAYS \"RC\" - Rows, Columns\n",
    "\n",
    "Axis 0 = Rows\n",
    "\n",
    "Axis 1 = Columns\n",
    "\n",
    "The main thing here, is that pandas and numpy indexing IS very similar, really, the only difference is that pandas just requires the extra \".loc\", whereas numpy does not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common indexing command\n",
    "df.iloc[:,:10]\n",
    "df = df.iloc[:,:10]\n",
    "# when indexing, the # here, is exactly the number of columns I want in the final dataset\n",
    "\n",
    "# if I want to only keep rows that fit a specific \"threshold\"\n",
    "# This syntax returns a dataframe full of true/false\n",
    "df = (df.iloc[:,:10] >= -.2) & (df.iloc[:,:10] <= .2)  \n",
    "\n",
    "# these two syntaxes both return the original values which meet the condition, \n",
    "# because its literally indexing in the original df[]\n",
    "# df.where() actually is the exact same function as df[]\n",
    "df = df[(df.iloc[:,:10] >= -.2) & (df.iloc[:,:10] <= .2)]\n",
    "df = df.where((df.iloc[:,:10] >= -.2) & (df.iloc[:,:10] <= .2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mastery of \"filtering\" by values\n",
    "So when it comes to filtering, although this feels inefficient... it appears that this must be done by individually popping out the columns in need of filtering, running a \"filter\" to only keep values in a certain range, and then rejoining these columns back to the original dataframe. I have searched far and wide for a way to do this more efficiently, even written a SO question on this, but at the moment this appears to be the only way to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering values in a target variable, and all feature columns\n",
    "def return_viable_samples(df):\n",
    "  # for each y value, verify if they lie in range [25-350], and drop the row if not\n",
    "    df_y = df.pop('labels')\n",
    "    df_y = df_y[(df_y >= 25) & (df_y <= 350)]\n",
    "    df_y.dropna(axis=0, inplace=True)\n",
    "    df_y = (df_y >= 140).astype(int)\n",
    "\n",
    "  # for each feature verify if they lie in the range [-0.2,0.2], and drop the row if not\n",
    "    df = df[(df.iloc[:,:10] >= -.2) & (df.iloc[:,:10] <= .2)]\n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    df['labels'] = df_y\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple dataframe things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c\n",
       "0  1  2  3\n",
       "1  4  5  6\n",
       "2  7  8  9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rounding all values in a dataframe: \n",
      "    a   b   c\n",
      "0   0   0   0\n",
      "1   0   0  10\n",
      "2  10  10  10\n",
      "\n",
      "unique values in \"a\": [1 4 7]\n",
      "\n",
      "number of unique values in a: 3 \n",
      "\n",
      "count of each unique value column \"a\": \n",
      "7    1\n",
      "1    1\n",
      "4    1\n",
      "Name: a, dtype: int64 \n",
      "\n",
      "percentage of each unique value in colunn \"a\": \n",
      "7    0.333333\n",
      "1    0.333333\n",
      "4    0.333333\n",
      "Name: a, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "display(df)\n",
    "\n",
    "print(f'rounding all values in a dataframe: \\n{df.round(-1)}\\n')\n",
    "\n",
    "print(f'unique values in \"a\": {pd.unique(df[\"a\"])}\\n')\n",
    "\n",
    "print(f'number of unique values in a: {len(pd.unique(df[\"a\"]))} \\n')\n",
    "\n",
    "#cprint(f'number of unique values in all columns: \\n{df.nunique(axis=0)} \\n', 'blue')\n",
    "\n",
    "print(f'count of each unique value column \"a\": \\n{df[\"a\"].value_counts()} \\n')\n",
    "\n",
    "print(f'percentage of each unique value in colunn \"a\": \\n{df[\"a\"].value_counts(normalize=True)} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concatinating dataframes ---- this function can do all the types of \"joins/appends\" needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_1, df_2])            # when no axis is specified, this is an \"append\" statement\n",
    "\n",
    "pd.concat([df_1, df_2], axis=1)    # when axis = 1, this is a \"join\" statement, an \"outer join\" by default"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
