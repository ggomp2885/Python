{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9380e004-38a4-46bb-9b21-a41c74fc48a0",
   "metadata": {},
   "source": [
    "# Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb1aa15-c0b7-4199-947b-01fff8c709fd",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d2a0543-11cc-4cc3-bda1-56d905277cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn                          # the pip packadge name is actually \"scikit-learn\"\n",
    "\n",
    "#training steps\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "xgb.set_config(verbosity=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115739be-53fb-4250-b2e6-6dbe80076ad3",
   "metadata": {},
   "source": [
    "## Creating mock classification data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4480aaf9-0d21-476c-9811-abe9ce84d223",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b141f9-48b7-443e-8d79-944f0829b73d",
   "metadata": {},
   "source": [
    "# Functions compatible with Pipeline object and cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e786cf8-3338-4d44-95d9-aa646a80714e",
   "metadata": {},
   "source": [
    "## Creating List of Pipeline objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "507999b1-5d65-453a-8a13-d17ed47cdd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('KNN', Pipeline([(\"scaling\", StandardScaler()), (\"model\", KNeighborsClassifier())])),\n",
    "          ('XGB', Pipeline([(\"scaling\", StandardScaler()), (\"model\", xgb.XGBClassifier(use_label_encoder=False))]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db141c74-0224-4e54-972a-23810ba76153",
   "metadata": {},
   "source": [
    "## GridsearchCV()\n",
    "The .fit() function is necessary here to actually compute the GridsearchCV function (the GridsearchCV() is like setting up a dictionary)\n",
    "The .fit() function is what finds the \".best_estimator_\" \n",
    "\n",
    "The GridsearchCV object natively becomes the best model found, there is no need to set it equal to the \"best_estimator_\", because this is already the default behavior\n",
    "\n",
    "The .predict() function is built in to use the \".best_estimator\"\n",
    "\n",
    "okay so I can see in the docs it says that if you call .predict() it will use the best model, but,\n",
    "does that mean it actually reruns the CV function everytime .predict() is called, to find it?\n",
    "Okay, yep, wow, this looks correct, so it should take about twice as long for this CV to run ontop of the GridCV thats already in the function\n",
    "Okay, yep, just about twice as long, so the model.best_estimator_ method is useful, or else it will just rerun the whole gridCV\n",
    "ah....... so the predict() function, does immediately use the \"best_estimator_\", however, the cross_val_score() function does not,\n",
    "so this is something to keep an eye on, and when in doubt, just add model.best_estimator_ onto it since this will always work\n",
    "\n",
    "The scoring method here defaults to accuracy if nothing is mentioned, and can be changed to whatever is needed, highest acc / precision / recall / f1, by setting the scoring argument, scoring = 'f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d753ac0d-e7c3-462a-8bae-f840799f962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gbc = GridSearchCV(estimator = models[8][1], \n",
    "                         param_grid = {'model__max_depth': [2,3,4,5,6,7],\n",
    "                                       'model__n_estimators': [12,25,50,100,150,200]},\n",
    "                         cv=10)\n",
    "\n",
    "model_gbc.fit(X, Y)\n",
    "print(f'highest mean cv score: {model_gbc.best_score_}, with params: {model_gbc.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57e2514-bdab-41cf-9f71-672b2951de50",
   "metadata": {},
   "source": [
    "## .predict() and .predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9304af-e6d2-4c68-b7aa-cc428dca6120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_preds = models[0][1].predict(X)\n",
    "# this is as simple as it gets, \n",
    "# returns back a list of the predictions made by the model after it has been fit.\n",
    "\n",
    "\n",
    "y_probability_preditions = estimator.predict_proba(X)        #often has a [:,1] at the end of this line to get just the positive probabilities only\n",
    "# This function returns a list that contains the probabilities for each of the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23093495-3c62-4bdc-936d-1bd5d70d1c17",
   "metadata": {},
   "source": [
    "## cross_val_score()\n",
    "is an evaluation metric for myself to see the results, I must include the .fit() function after this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c705ba-f7b1-4886-a211-03668da4809f",
   "metadata": {},
   "source": [
    "## cross_val_predict() with 'predict_proba' example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a548e89-7231-4d02-be37-33315af943d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this does exactly what I would expect it to do,\n",
    "# createing a list, appending the predictions made on each fold to this list, \n",
    "# so it can be compared with the true values in the same order\n",
    "y_preds_gbc = cross_val_predict(model.best_estimator_, X, Y, cv=10)    # The default cv method here is stratified K-fold with shuffle=False so it is a repeatable result\n",
    "\n",
    "\n",
    "# this one returns the raw probability scores outputed by the model\n",
    "# the [:,1] indexing here is to return just the postive case probability scores\n",
    "y_pred_probs_gbc = cross_val_predict(model_gbc.best_estimator_, X, Y, cv=10, method='predict_proba')[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7040a7e8-f06a-40b7-add2-1ec10f57d6f7",
   "metadata": {},
   "source": [
    "## confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab0c61-d631-42b8-b094-290ecf403cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember, sklearns confusion matrix has the TN and TP's flipped\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d691f16-70b8-4520-a1e7-f0c366576ce4",
   "metadata": {},
   "source": [
    "## learning_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc14c3c5-98f8-4514-8115-dd0095304091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "model = xgb.XGBClassifier(objective = 'multi:softprob', num_class=5)\n",
    "train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(model, X, Y, cv=5,\n",
    "                                                                      return_times=True,\n",
    "                                                                      train_sizes=np.linspace(.005, .06, 10),\n",
    "                                                                      shuffle=True, random_state =1)\n",
    "\n",
    "plt.plot(train_sizes, np.mean(train_scores, axis=1), label='Train Score')\n",
    "plt.plot(train_sizes, np.mean(test_scores, axis=1), label='Test Score')\n",
    "plt.plot(train_sizes, np.mean(fit_times, axis=1), label='Time')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e3e843-b5c2-4816-a59c-da6f82fffe50",
   "metadata": {},
   "source": [
    "# Manual functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45e0382-a447-4a17-8400-d2dfec5dbf98",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cb1a28-6043-41d4-8a5d-a3c417daf4c7",
   "metadata": {},
   "source": [
    "## Iterative Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a807640-41f6-44dd-be70-aff0ce6e2973",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before Iterative imputer: ')\n",
    "display(df_3.head(3))\n",
    "\n",
    "imputer = IterativeImputer(max_iter=30, random_state = 0, min_value = 0)\n",
    "# imputer = KNNImputer(n_neighbors=8)\n",
    "df_4 = pd.DataFrame(imputer.fit_transform(df_3), columns= df_3.columns)\n",
    "\n",
    "print('After Iterative Imputer: ')\n",
    "display(df_4.head(3))\n",
    "print(df_4.shape)\n",
    "print(f'total null values after iterative imputer: {df_4.isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af50032-ca48-4c78-b64e-f5eb96c5f49a",
   "metadata": {},
   "source": [
    "# Other Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cf68bd-f9ce-4412-a727-9a54102a18d8",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5b5918-5411-46a1-9961-e3bc12a889c9",
   "metadata": {},
   "source": [
    "## Listing all classification models in SKlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b954ba4-39d7-4523-8cbd-a03a94070229",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.utils import all_estimators\n",
    "\n",
    "classifiers = [est for est in all_estimators() if issubclass(est[1], ClassifierMixin)]\n",
    "display(classifiers)\n",
    "\n",
    "# simple import code for 20 of the 40 models available\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble._weight_boosting import AdaBoostClassifier\n",
    "from sklearn.ensemble._bagging import BaggingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.tree._classes import DecisionTreeClassifier\n",
    "from sklearn.ensemble._forest import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble._gb import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm._classes import LinearSVC\n",
    "from sklearn.linear_model._logistic import LogisticRegression\n",
    "from sklearn.neural_network._multilayer_perceptron import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm._classes import NuSVC\n",
    "from sklearn.linear_model._passive_aggressive import PassiveAggressiveClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble._forest import RandomForestClassifier\n",
    "from sklearn.linear_model._ridge import RidgeClassifier\n",
    "from sklearn.linear_model._stochastic_gradient import SGDClassifier\n",
    "from sklearn.svm._classes import SVC\n",
    "from sklearn.ensemble._stacking import StackingClassifier\n",
    "from sklearn.ensemble._voting import VotingClassifier\n",
    "import xgboost as xgb\n",
    "xgb.set_config(verbosity=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
